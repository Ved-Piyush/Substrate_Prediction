{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "36ac295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "7445edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "69ba8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "5ef9de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the train\n",
    "train = pd.read_csv(r\"D:\\Fake News\\fake news detection(FakeNewsNet)\\fnn_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "f2908703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "validation = pd.read_csv(r\"D:\\Fake News\\fake news detection(FakeNewsNet)\\fnn_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f0a05a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test = pd.read_csv(r\"D:\\Fake News\\fake news detection(FakeNewsNet)\\fnn_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "dc916475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have an input layer\n",
    "input_layer = tf.keras.layers.Input(shape = (), dtype = tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "3c5c7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "4dbc4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass this to a vectorization layer\n",
    "# but first make a vectorization layer\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens = max_tokens, output_mode = \"int\",\n",
    "                                                  output_sequence_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "4003b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer.adapt(train[\"fullText_based_content\"], batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "5802bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the input through this text vectorization layer\n",
    "vectorized_text = text_vec_layer(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "3634e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an embedding layer\n",
    "emb_layer = tf.keras.layers.Embedding(max_tokens, 100, mask_zero = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "902b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the vectorized text through the embedding layer\n",
    "emb_output = emb_layer(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "ea4536de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some spatial dropout?\n",
    "# spatial_dropout = tf.keras.layers.SpatialDropout1D(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "a91636d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial dropout output\n",
    "# spatial_dropout_output = spatial_dropout(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "decb89bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a recurrent layer\n",
    "gru_layer = tf.keras.layers.LSTM(50, dropout = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "2810a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the emb output through the gru\n",
    "gru_output = gru_layer(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "03862e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout layer\n",
    "dropout_layer = tf.keras.layers.Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "30275434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout output\n",
    "dropout_output = dropout_layer(gru_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "8207b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification layer\n",
    "classification_layer = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "0e7a97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class output\n",
    "class_output = classification_layer(gru_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "4864b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the model\n",
    "model = tf.keras.models.Model(input_layer, class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "6c3c21ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_13 (TextV (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 100, 100)          200000    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 230,251\n",
      "Trainable params: 230,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7ed10acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits=True), \n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-2), \n",
    "             metrics=tf.keras.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "dac41d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "1b02e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "297db55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = le.fit_transform(train[\"label_fnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "7c61d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_valid = le.transform(validation[\"label_fnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "da74eb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_combined = pd.concat([train[\"fullText_based_content\"], validation[\"fullText_based_content\"]], \n",
    "                                     ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "19487a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_target = pd.concat([pd.DataFrame(targets_train), pd.DataFrame(targets_valid)], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "7bdeaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_target.columns = [\"fnn_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "73e0c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_test = le.transform(test[\"label_fnn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "291e1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "1344753a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "115/115 [==============================] - 11s 70ms/step - loss: 0.6811 - binary_accuracy: 0.5079 - val_loss: 0.6708 - val_binary_accuracy: 0.5028\n",
      "Epoch 2/200\n",
      "115/115 [==============================] - 7s 60ms/step - loss: 0.6397 - binary_accuracy: 0.5840 - val_loss: 0.6516 - val_binary_accuracy: 0.5937\n",
      "Epoch 3/200\n",
      "115/115 [==============================] - 7s 60ms/step - loss: 0.5986 - binary_accuracy: 0.6445 - val_loss: 0.6793 - val_binary_accuracy: 0.5796\n",
      "Epoch 4/200\n",
      "115/115 [==============================] - 7s 60ms/step - loss: 0.5752 - binary_accuracy: 0.6606 - val_loss: 0.6824 - val_binary_accuracy: 0.5833\n",
      "Epoch 5/200\n",
      "115/115 [==============================] - 7s 60ms/step - loss: 0.5376 - binary_accuracy: 0.6985 - val_loss: 0.7379 - val_binary_accuracy: 0.5925\n",
      "Epoch 6/200\n",
      "115/115 [==============================] - 7s 60ms/step - loss: 0.5065 - binary_accuracy: 0.7203 - val_loss: 0.7483 - val_binary_accuracy: 0.5925\n",
      "Epoch 7/200\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.4730 - binary_accuracy: 0.7463 - val_loss: 0.7943 - val_binary_accuracy: 0.5974\n",
      "Epoch 8/200\n",
      "115/115 [==============================] - 9s 75ms/step - loss: 0.4564 - binary_accuracy: 0.7550 - val_loss: 0.8246 - val_binary_accuracy: 0.5704\n",
      "Epoch 9/200\n",
      "115/115 [==============================] - 8s 74ms/step - loss: 0.4403 - binary_accuracy: 0.7721 - val_loss: 0.8836 - val_binary_accuracy: 0.6030\n",
      "Epoch 10/200\n",
      "115/115 [==============================] - 8s 74ms/step - loss: 0.4230 - binary_accuracy: 0.7835 - val_loss: 0.9587 - val_binary_accuracy: 0.5759\n",
      "Epoch 11/200\n",
      "115/115 [==============================] - 9s 75ms/step - loss: 0.4116 - binary_accuracy: 0.7923 - val_loss: 0.9604 - val_binary_accuracy: 0.5839\n",
      "Epoch 12/200\n",
      "115/115 [==============================] - 8s 73ms/step - loss: 0.4132 - binary_accuracy: 0.7886 - val_loss: 0.9708 - val_binary_accuracy: 0.5821\n",
      "Epoch 13/200\n",
      "115/115 [==============================] - 8s 72ms/step - loss: 0.4054 - binary_accuracy: 0.7985 - val_loss: 0.9703 - val_binary_accuracy: 0.5974\n",
      "Epoch 14/200\n",
      "115/115 [==============================] - 8s 66ms/step - loss: 0.3982 - binary_accuracy: 0.8009 - val_loss: 1.0056 - val_binary_accuracy: 0.6060\n",
      "Epoch 15/200\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.3872 - binary_accuracy: 0.8074 - val_loss: 1.0694 - val_binary_accuracy: 0.6017\n",
      "Epoch 16/200\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.3857 - binary_accuracy: 0.8091 - val_loss: 1.0620 - val_binary_accuracy: 0.5833\n",
      "Epoch 17/200\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.3856 - binary_accuracy: 0.8107 - val_loss: 1.0477 - val_binary_accuracy: 0.5814\n",
      "Epoch 18/200\n",
      "115/115 [==============================] - 7s 64ms/step - loss: 0.3814 - binary_accuracy: 0.8121 - val_loss: 1.0752 - val_binary_accuracy: 0.5704\n",
      "Epoch 19/200\n",
      "115/115 [==============================] - 7s 65ms/step - loss: 0.3775 - binary_accuracy: 0.8168 - val_loss: 1.0906 - val_binary_accuracy: 0.5722\n",
      "Epoch 20/200\n",
      "115/115 [==============================] - 8s 74ms/step - loss: 0.3799 - binary_accuracy: 0.8155 - val_loss: 1.0731 - val_binary_accuracy: 0.5821\n",
      "Epoch 21/200\n",
      " 58/115 [==============>...............] - ETA: 4s - loss: 0.3671 - binary_accuracy: 0.8231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3996/194476359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.fit(train_validation_combined.values, np.array(train_valid_target[\"fnn_label\"]), verbose = 1, batch_size = 128, \n\u001b[0m\u001b[0;32m      3\u001b[0m          \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m          epochs = 200, callbacks = tf.keras.callbacks.EarlyStopping(monitor = \"val_binary_accuracy\", \n\u001b[0;32m      5\u001b[0m                                                                    \u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"max\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\newone\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(train_validation_combined.values, np.array(train_valid_target[\"fnn_label\"]), verbose = 1, batch_size = 128, \n",
    "         validation_split = 0.1, \n",
    "         epochs = 200, callbacks = tf.keras.callbacks.EarlyStopping(monitor = \"val_binary_accuracy\", \n",
    "                                                                   patience = 10, mode = \"max\",\n",
    "                                                                    restore_best_weights = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88905077",
   "metadata": {},
   "outputs": [],
   "source": [
    "636/(636 + 418)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "c3968322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 17ms/step - loss: 0.8394 - binary_accuracy: 0.6509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.839396059513092, 0.6508538722991943]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test[\"fullText_based_content\"].values, targets_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newone",
   "language": "python",
   "name": "newone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
