{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7182c3d8",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f282d",
   "metadata": {},
   "source": [
    "**Multi-Class Classification** - To classify a sequence of genes into different categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c44589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory to where the data is\n",
    "import os\n",
    "\n",
    "os.chdir(r\"D:\\Gene_Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e62277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas for dealing with the data\n",
    "import pandas as pd\n",
    "# setting for seeing the entire string\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - new data that was provided\n",
    "data = pd.read_csv(r\"pul_seq_low_high_substr_year_corrected.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd29d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"high_level_substr\"] == 'multiple_substrates'][\"low_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da107307",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = list(data[\"high_level_substr\"].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efe352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81046c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correspondence between high and low level\n",
    "\n",
    "for classes in all_classes: \n",
    "    print(classes)\n",
    "    filtered_data = data[data[\"high_level_substr\"] == classes]\n",
    "    correspondence = np.mean(filtered_data[\"high_level_substr\"].values == filtered_data[\"low_level_substr\"].values)\n",
    "    print(correspondence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55266a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"low_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2545bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data[\"high_level_substr\"] == \"multiple_substrates\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97191071",
   "metadata": {},
   "source": [
    "## Some data issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d713f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some null gene sequence\n",
    "# was creating some bugs later in the code\n",
    "# removed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.isnull().sum(axis = 1).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc0fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a466b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.isnull().sum(axis = 1).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give column names\n",
    "# data.columns = [\"sequence\", \"target\", \"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop year\n",
    "# data = data.drop(labels = \"year\",axis = 1).sample(frac = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135494f1",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a6a9b",
   "metadata": {},
   "source": [
    "1. Check the distribution of the substrates. \n",
    "2. Learn something about the genes that appear in the sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d7667",
   "metadata": {},
   "source": [
    "## Check the target distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e50377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low level vs high level\n",
    "# low level has 170 categories \n",
    "# probably not amenable for multi class classification\n",
    "data[\"low_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0293d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"low_level_substr\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the missing class? that is the one which just says \"-\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77766c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"high_level_substr\"] == \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5723ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"high_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are there? \n",
    "# much more manageable - 26\n",
    "# this is what we will use for the multi class classification\n",
    "len(data[\"high_level_substr\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536cf53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency counts\n",
    "D = data.high_level_substr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a dictionary\n",
    "D = dict(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33876692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the plotting packages\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31457d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters for improved plotting aesthetics\n",
    "mpl.rcParams['xtick.labelsize'] = 15 \n",
    "plt.rcParams[\"font.weight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the plotting area\n",
    "plt.figure(figsize = (10,6))\n",
    "# need a bar plot\n",
    "plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "# put the labels but rotate them\n",
    "plt.xticks(range(len(D)), list(D.keys()), rotation = 90, weight = \"bold\")\n",
    "# increase the ticks on y\n",
    "plt.yticks(fontsize=14)\n",
    "# give labels to x\n",
    "plt.xlabel(\"Target Classes\", weight = \"bold\", fontsize = 20)\n",
    "# give labels to y\n",
    "plt.ylabel(\"Frequency\", weight = \"bold\", fontsize = 20)\n",
    "# put the title\n",
    "plt.title(\"Frequencies for the target classes\", weight = \"bold\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca71ee",
   "metadata": {},
   "source": [
    "## What about the genes in the sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30849619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all the genes from each sequence\n",
    "all_genes_per_sequence = [str(seq).split(\",\") for seq in data[\"sig_gene_seq\"]]\n",
    "# loop over the list of genes and flatten it\n",
    "all_genes = [gene for list_genes in all_genes_per_sequence for gene in list_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19538b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy to deal with arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique genes? \n",
    "len(np.unique(all_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import counter function\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2081394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency counts\n",
    "freq_count = Counter(all_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233409a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"-\" in freq_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in descending order\n",
    "D =dict(sorted(freq_count.items(), key=lambda item: item[1], reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06335d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate for plotting\n",
    "first2pairs = {k: D[k] for k in list(D)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80661f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable assignment\n",
    "D = first2pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7491f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some parameters for improved plotting aesthetics\n",
    "mpl.rcParams['xtick.labelsize'] = 15 \n",
    "plt.rcParams[\"font.weight\"] = \"bold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d87243",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "plt.title(\"Frequency distribution for genes\", fontsize = 20)\n",
    "plt.xlabel(\"Gene Index\", fontsize = 20)\n",
    "plt.ylabel(\"Frequency\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ce665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the cdf\n",
    "cdf_vec = np.cumsum(list(D.values()))/np.cumsum(list(D.values()))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d55bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot for the cdf\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.bar(range(len(cdf_vec)), cdf_vec, align='center')\n",
    "plt.title(\"CDF for the Frequency Counts\", fontsize = 20)\n",
    "plt.xlabel(\"Gene Index\", fontsize = 20)\n",
    "plt.ylabel(\"Frequency\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c3250",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe297f",
   "metadata": {},
   "source": [
    "## How many classes can we handle for greater than 80% accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d717292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the requisite packages\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function that takes in the data and number of classes\n",
    "def model_by_classes(num_classes, data, both = False, split_on_bar = False): \n",
    "    # get the frequency counts\n",
    "    all_classes = list(data.high_level_substr.value_counts().keys())\n",
    "    # remove multiple substrates\n",
    "#     all_classes = [classes for classes in all_classes if classes not in [\"multiple_substrates\"]]\n",
    "    # suppose using the top 2\n",
    "    keep_these_many = num_classes\n",
    "    # top_k_classes\n",
    "    top_k = all_classes[:keep_these_many]\n",
    "    # not top two\n",
    "    not_top_k = [target for target in all_classes if target not in top_k]\n",
    "    # get the data for the top k classes\n",
    "    top_k_data = data[data.high_level_substr.isin(top_k)].reset_index(drop = True)\n",
    "    # get the data for the non top_k classes\n",
    "    not_top_k_data = data[data.high_level_substr.isin(not_top_k)].reset_index(drop = True)\n",
    "    # give the same label to all the targets of the not_top_k_data\n",
    "    not_top_k_data[\"high_level_substr\"] = \"other\"\n",
    "    # stack the top k and the not top k data together\n",
    "    all_data = pd.concat([top_k_data, not_top_k_data], ignore_index = True)\n",
    "    \n",
    "    if split_on_bar == False:\n",
    "        # instantiate the vectorizer again\n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)\n",
    "    \n",
    "    else: \n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).replace(\"|\", \",\").split(','), lowercase = False)\n",
    "    \n",
    "    # pipeline\n",
    "    clf = Pipeline([('countvectorizer',vectorizer),('rf',RandomForestClassifier(n_jobs = 6))])\n",
    "    # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "    param_grid = {\n",
    "    'countvectorizer__min_df': [1,2],\n",
    "    'rf__n_estimators': [100,200,400], \n",
    "    'rf__max_features': [\"auto\", \"log2\"]\n",
    "    }\n",
    "    # fit the search\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=7 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "    \n",
    "    # if both gene seq and category seq\n",
    "    \n",
    "    if both == True: \n",
    "        # fit the grid search\n",
    "        search.fit(all_data[\"sig_gene_seq\"] + \",\" + all_data[\"category_sequence\"], all_data[\"high_level_substr\"])\n",
    "    else: \n",
    "        search.fit(all_data[\"sig_gene_seq\"], all_data[\"high_level_substr\"])\n",
    "    # best score\n",
    "    best_score = search.best_score_\n",
    "    # std error\n",
    "    std_accuracy = search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]\n",
    "    vectorizer.fit_transform(all_data[\"sig_gene_seq\"])\n",
    "    print(len(vectorizer.vocabulary_))\n",
    "    return num_classes, best_score, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that can help us do parallel computation\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b2825",
   "metadata": {},
   "source": [
    "### only using gene data and not splitting on bar (\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function in parallel\n",
    "all_results = Parallel(n_jobs=7, verbose = 2)(delayed(model_by_classes)(i, data, False, False) for i in range(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the error ranges\n",
    "err_ranges = np.array(all_results)[:,2]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1271a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything in a dataframe\n",
    "df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb687b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give column names\n",
    "df.columns = [\"num_classes\", \"mean_accuracy\", \"std_error_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a10c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data do these classes cover\n",
    "coverage = pd.DataFrame(data.high_level_substr.value_counts().cumsum()/data.high_level_substr.value_counts().cumsum()[-1])[\"high_level_substr\"].values[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad61852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the coverage\n",
    "coverage = np.round(coverage,2).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.errorbar(df[\"num_classes\"],np.array(all_results)[:,1], \n",
    "             err_ranges, linestyle='None', marker='^', linewidth = 2)\n",
    "plt.xlabel(\"Number of Classes\", weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", weight = \"bold\", fontsize = 20)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(df[\"num_classes\"])\n",
    "counter = 2\n",
    "plt.title(\"mean accuracy with +- 3 SD\", weight = \"bold\", fontsize = 20)\n",
    "for text in coverage: \n",
    "    plt.text(counter, .85, text)\n",
    "    counter+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10127906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column for coverage\n",
    "df[\"coverage\"] = coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06407cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_classes\"] = df[\"num_classes\"]  + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719be626",
   "metadata": {},
   "source": [
    "## remove multiple substrates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13391ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function that takes in the data and number of classes\n",
    "def model_by_classes(num_classes, data, both = False, split_on_bar = False): \n",
    "    # get the frequency counts\n",
    "    all_classes = list(data.high_level_substr.value_counts().keys())\n",
    "    # remove multiple substrates\n",
    "    all_classes = [classes for classes in all_classes if classes not in [\"multiple_substrates\"]]\n",
    "    # suppose using the top 2\n",
    "    keep_these_many = num_classes\n",
    "    # top_k_classes\n",
    "    top_k = all_classes[:keep_these_many]\n",
    "    # not top two\n",
    "    not_top_k = [target for target in all_classes if target not in top_k]\n",
    "    # get the data for the top k classes\n",
    "    top_k_data = data[data.high_level_substr.isin(top_k)].reset_index(drop = True)\n",
    "    # get the data for the non top_k classes\n",
    "    not_top_k_data = data[data.high_level_substr.isin(not_top_k)].reset_index(drop = True)\n",
    "    # give the same label to all the targets of the not_top_k_data\n",
    "    not_top_k_data[\"high_level_substr\"] = \"other\"\n",
    "    # stack the top k and the not top k data together\n",
    "    all_data = pd.concat([top_k_data, not_top_k_data], ignore_index = True)\n",
    "    \n",
    "    if split_on_bar == False:\n",
    "        # instantiate the vectorizer again\n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)\n",
    "    \n",
    "    else: \n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).replace(\"|\", \",\").split(','), lowercase = False)\n",
    "    \n",
    "    # pipeline\n",
    "    clf = Pipeline([('countvectorizer',vectorizer),('rf',RandomForestClassifier(n_jobs = 6))])\n",
    "    # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "    param_grid = {\n",
    "    'countvectorizer__min_df': [1,2],\n",
    "    'rf__n_estimators': [100,200,400], \n",
    "    'rf__max_features': [\"auto\", \"log2\"]\n",
    "    }\n",
    "    # fit the search\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=7 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "    \n",
    "    # if both gene seq and category seq\n",
    "    \n",
    "    if both == True: \n",
    "        # fit the grid search\n",
    "        search.fit(all_data[\"sig_gene_seq\"] + \",\" + all_data[\"category_sequence\"], all_data[\"high_level_substr\"])\n",
    "    else: \n",
    "        search.fit(all_data[\"sig_gene_seq\"], all_data[\"high_level_substr\"])\n",
    "    # best score\n",
    "    best_score = search.best_score_\n",
    "    # std error\n",
    "    std_accuracy = search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]\n",
    "    vectorizer.fit_transform(all_data[\"sig_gene_seq\"])\n",
    "    print(len(vectorizer.vocabulary_))\n",
    "    return num_classes, best_score, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af449424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that can help us do parallel computation\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac77e7",
   "metadata": {},
   "source": [
    "### only using gene data and not splitting on bar (\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function in parallel\n",
    "all_results = Parallel(n_jobs=7, verbose = 2)(delayed(model_by_classes)(i, data, False, False) for i in range(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fa014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the error ranges\n",
    "err_ranges = np.array(all_results)[:,2]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeba92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything in a dataframe\n",
    "df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give column names\n",
    "df.columns = [\"num_classes\", \"mean_accuracy\", \"std_error_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e738d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data do these classes cover\n",
    "coverage = pd.DataFrame(data.high_level_substr.value_counts().cumsum()/data.high_level_substr.value_counts().cumsum()[-1])[\"high_level_substr\"].values[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d741eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the coverage\n",
    "coverage = np.round(coverage,2).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.errorbar(df[\"num_classes\"],np.array(all_results)[:,1], \n",
    "             err_ranges, linestyle='None', marker='^', linewidth = 2)\n",
    "plt.xlabel(\"Number of Classes\", weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", weight = \"bold\", fontsize = 20)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(df[\"num_classes\"])\n",
    "counter = 1\n",
    "plt.title(\"mean accuracy with +- 3 SD\", weight = \"bold\", fontsize = 20)\n",
    "for text in coverage: \n",
    "    plt.text(counter, 1, text)\n",
    "    counter+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e63404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column for coverage\n",
    "df[\"coverage\"] = coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a485cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_classes\"] = df[\"num_classes\"]  + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1c0fd",
   "metadata": {},
   "source": [
    "We could decide to work with the top 2 or 3 most frequent classes because those models have an accuracy of over 70% but the issue is that the top 2 or 3 most frequent classes only cover about ~50% of the data which I do not think is enough coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e53463",
   "metadata": {},
   "source": [
    "We got some more data which essentially maps each gene to a reference. We will do the same kind of exercise as done above, but with the addition of this signature gene reference data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f062bc7",
   "metadata": {},
   "source": [
    "### only using gene data and splitting on bar (\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function in parallel\n",
    "all_results = Parallel(n_jobs=7, verbose = 2)(delayed(model_by_classes)(i, data, False, True) for i in range(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the error ranges\n",
    "err_ranges = np.array(all_results)[:,2]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521601a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything in a dataframe\n",
    "df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747adacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give column names\n",
    "df.columns = [\"num_classes\", \"mean_accuracy\", \"std_error_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a98413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data do these classes cover\n",
    "coverage = pd.DataFrame(data.high_level_substr.value_counts().cumsum()/data.high_level_substr.value_counts().cumsum()[-1])[\"high_level_substr\"].values[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad61852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the coverage\n",
    "coverage = np.round(coverage,2).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.errorbar(df[\"num_classes\"],np.array(all_results)[:,1], \n",
    "             err_ranges, linestyle='None', marker='^', linewidth = 2)\n",
    "plt.xlabel(\"Number of Classes\", weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", weight = \"bold\", fontsize = 20)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(df[\"num_classes\"])\n",
    "counter = 1\n",
    "plt.title(\"mean accuracy with +- 3 SD\", weight = \"bold\", fontsize = 20)\n",
    "for text in coverage: \n",
    "    plt.text(counter, 1, text)\n",
    "    counter+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10127906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column for coverage\n",
    "df[\"coverage\"] = coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06407cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num_classes\"] = df[\"num_classes\"]  + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab1c0fd",
   "metadata": {},
   "source": [
    "We could decide to work with the top 2 or 3 most frequent classes because those models have an accuracy of over 70% but the issue is that the top 2 or 3 most frequent classes only cover about ~50% of the data which I do not think is enough coverage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e53463",
   "metadata": {},
   "source": [
    "We got some more data which essentially maps each gene to a reference. We will do the same kind of exercise as done above, but with the addition of this signature gene reference data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd6ba1",
   "metadata": {},
   "source": [
    "## adding the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the signature gene reference data\n",
    "sig_gene_reference = pd.read_csv(r\"signature_gene_reference.tsv\", sep = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48a7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the columns\n",
    "sig_gene_reference.columns = [\"category\", \"gene\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first few rows of the data\n",
    "sig_gene_reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e505f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the distinctive categories\n",
    "sig_gene_reference[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to map the genes to the category\n",
    "def map_genes_to_categories(sequence): \n",
    "    # instantiate an empty string\n",
    "    category_sequence = \"\"\n",
    "    # the category data has individual genes like A and B and not A|B\n",
    "    # thus to have all the genes mapped we would need to replace \"|\" by \",\"\n",
    "    \n",
    "    # replace \"|\" with a \",\" and then split on the \",\"\n",
    "    # iterate over all those genes\n",
    "    for gene in str(sequence).replace(\"|\", \",\").split(\",\"):\n",
    "        # map out the category reference for the gene\n",
    "        categories = sig_gene_reference[sig_gene_reference[\"gene\"] == gene][\"category\"].values\n",
    "        # sometimes one gene can have different categories\n",
    "        # in such a case loop over the multiple categories found\n",
    "        for i in categories: \n",
    "            # iteratively add to the empty string\n",
    "#             if len(i) > 0:\n",
    "            category_sequence = category_sequence + \",\" + i\n",
    "    # there would be a weird comma at the very start character\n",
    "    # remove that and keep the rest\n",
    "    return category_sequence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1189d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d10d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_sequence = []\n",
    "for sequence in tqdm(data[\"sig_gene_seq\"].values): \n",
    "    category_sequence.append(map_genes_to_categories(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3579d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"category_sequence\"] = category_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b589019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44959ece",
   "metadata": {},
   "source": [
    "### Using both gene and category data and not splitting on bar (\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca288c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function in parallel\n",
    "all_results = Parallel(n_jobs=7, verbose = 2)(delayed(model_by_classes)(i, data, True, False) for i in range(1, 10))\n",
    "\n",
    "# get the error ranges\n",
    "err_ranges = np.array(all_results)[:,2]*3\n",
    "\n",
    "# put everything in a dataframe\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# give column names\n",
    "df.columns = [\"num_classes\", \"mean_accuracy\", \"std_error_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data do these classes cover\n",
    "coverage = pd.DataFrame(data.high_level_substr.value_counts().cumsum()/data.high_level_substr.value_counts().cumsum()[-1])[\"high_level_substr\"].values[1:10]\n",
    "\n",
    "# round the coverage\n",
    "coverage = np.round(coverage,2).astype(str)\n",
    "\n",
    "# create a plot\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.errorbar(df[\"num_classes\"],np.array(all_results)[:,1], \n",
    "             err_ranges, linestyle='None', marker='^', linewidth = 2)\n",
    "plt.xlabel(\"Number of Classes\", weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", weight = \"bold\", fontsize = 20)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(df[\"num_classes\"])\n",
    "counter = 1\n",
    "plt.title(\"mean accuracy with +- 3 SD\", weight = \"bold\", fontsize = 20)\n",
    "for text in coverage: \n",
    "    plt.text(counter, 1, text)\n",
    "    counter+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c229bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column for coverage\n",
    "df[\"coverage\"] = coverage\n",
    "\n",
    "df[\"num_classes\"] = df[\"num_classes\"]  + 1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2817c7",
   "metadata": {},
   "source": [
    "### Using both gene and category data and splitting on bar (\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's focus on this one\n",
    "data[\"sig_gene_seq\"].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088bb742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what we have been doing so far\n",
    "data[\"sig_gene_seq\"].values[2].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or could there be some basis for doing something like this as well?\n",
    "data[\"sig_gene_seq\"].values[2].replace(\"|\", \",\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e675a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function in parallel\n",
    "all_results = Parallel(n_jobs=7, verbose = 2)(delayed(model_by_classes)(i, data, True, True) for i in range(1, 10))\n",
    "\n",
    "# get the error ranges\n",
    "err_ranges = np.array(all_results)[:,2]*3\n",
    "\n",
    "# put everything in a dataframe\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# give column names\n",
    "df.columns = [\"num_classes\", \"mean_accuracy\", \"std_error_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4656602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data do these classes cover\n",
    "coverage = pd.DataFrame(data.high_level_substr.value_counts().cumsum()/data.high_level_substr.value_counts().cumsum()[-1])[\"high_level_substr\"].values[1:10]\n",
    "\n",
    "# round the coverage\n",
    "coverage = np.round(coverage,2).astype(str)\n",
    "\n",
    "# create a plot\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.errorbar(df[\"num_classes\"],np.array(all_results)[:,1], \n",
    "             err_ranges, linestyle='None', marker='^', linewidth = 2)\n",
    "plt.xlabel(\"Number of Classes\", weight = \"bold\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", weight = \"bold\", fontsize = 20)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(df[\"num_classes\"])\n",
    "counter = 1\n",
    "plt.title(\"mean accuracy with +- 3 SD\", weight = \"bold\", fontsize = 20)\n",
    "for text in coverage: \n",
    "    plt.text(counter, 1, text)\n",
    "    counter+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01fbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column for coverage\n",
    "df[\"coverage\"] = coverage\n",
    "\n",
    "df[\"num_classes\"] = df[\"num_classes\"]  + 1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b1d10",
   "metadata": {},
   "source": [
    "Therefore, the roadmap we will use is, we would have a classification model that can classify sequences into these top 6 most frequent classes. We would also have an unknown class in the mix which the model would classify a sequence into if it is not sure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee281aec",
   "metadata": {},
   "source": [
    "## Implementing the roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ea18d",
   "metadata": {},
   "source": [
    "### use only gene data, no metadata and split on bars as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc96be5",
   "metadata": {},
   "source": [
    "### RandomForest Supervised Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data[\"high_level_substr\"].isin([\"multiple_substrates\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"sig_gene_seq\"], data[\"high_level_substr\"],\n",
    "                                                    test_size=0.30, random_state=42, stratify = data[\"high_level_substr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function that takes in the data and number of classes\n",
    "def model_by_classes(num_classes, data, both = False, split_on_bar = False): \n",
    "    # get the frequency counts\n",
    "    all_classes = list(data.high_level_substr.value_counts().keys())\n",
    "    # remove multiple substrates\n",
    "#     all_classes = [classes for classes in all_classes if classes not in [\"multiple_substrates\"]]\n",
    "    # suppose using the top 2\n",
    "    keep_these_many = num_classes\n",
    "    # top_k_classes\n",
    "    top_k = all_classes[:keep_these_many]\n",
    "    # not top two\n",
    "    not_top_k = [target for target in all_classes if target not in top_k]\n",
    "    # get the data for the top k classes\n",
    "    top_k_data = data[data.high_level_substr.isin(top_k)].reset_index(drop = True)\n",
    "    # get the data for the non top_k classes\n",
    "    not_top_k_data = data[data.high_level_substr.isin(not_top_k)].reset_index(drop = True)\n",
    "    # give the same label to all the targets of the not_top_k_data\n",
    "    not_top_k_data[\"high_level_substr\"] = \"other\"\n",
    "    # stack the top k and the not top k data together\n",
    "    all_data = pd.concat([top_k_data, not_top_k_data], ignore_index = True)\n",
    "    \n",
    "    if split_on_bar == False:\n",
    "        # instantiate the vectorizer again\n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)\n",
    "    \n",
    "    else: \n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).replace(\"|\", \",\").split(','), lowercase = False)\n",
    "    \n",
    "    # pipeline\n",
    "    clf = Pipeline([('countvectorizer',vectorizer),('rf',RandomForestClassifier(n_jobs = 6))])\n",
    "    # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "    param_grid = {\n",
    "    'countvectorizer__min_df': [1,2],\n",
    "    'rf__n_estimators': [100,200,400], \n",
    "    'rf__max_features': [\"auto\", \"log2\"]\n",
    "    }\n",
    "    # fit the search\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=7 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "    \n",
    "    # if both gene seq and category seq\n",
    "    \n",
    "    if both == True: \n",
    "        # fit the grid search\n",
    "        search.fit(all_data[\"sig_gene_seq\"] + \",\" + all_data[\"category_sequence\"], all_data[\"high_level_substr\"])\n",
    "    else: \n",
    "        search.fit(all_data[\"sig_gene_seq\"], all_data[\"high_level_substr\"])\n",
    "    # best score\n",
    "    best_score = search.best_score_\n",
    "    # std error\n",
    "    std_accuracy = search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]\n",
    "    vectorizer.fit_transform(all_data[\"sig_gene_seq\"])\n",
    "    print(len(vectorizer.vocabulary_))\n",
    "    return num_classes, best_score, std_accuracy, search.best_estimator_, top_k, not_top_k, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([pd.DataFrame(X_train.values), pd.DataFrame(y_train.values)], ignore_index = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns = [\"sig_gene_seq\", \"high_level_substr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function with 6 classes and only train data\n",
    "num_classes, best_score, std_accuracy, best_estimator_, top_k, not_top_k, vectorizer = model_by_classes(5, data_train, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57872d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score and std error\n",
    "best_score, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column change the original targets to top 6 + unknown\n",
    "targets_train = [target if target in top_k else \"other\" for target in data_train[\"high_level_substr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ac0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0377a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit this best estimator\n",
    "best_estimator.fit(data_train[[\"sig_gene_seq\"]].values, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(targets_train, best_estimator.predict(data_train[[\"sig_gene_seq\"]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac498386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for test\n",
    "y_test_pred = best_estimator.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0620242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column change the original targets to top 6 + unknown\n",
    "targets_test = [target if target in top_k else \"other\" for target in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.concat([pd.DataFrame(X_test.values), pd.DataFrame(targets_test)], ignore_index = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c091b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns = [\"sig_gene_seq\", \"high_level_substr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73637e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column change the original targets to top 6 + unknown\n",
    "# targets_test = [target if target in top_k else \"other\" for target in data_test[\"high_level_substr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the array oaf confusion matrix\n",
    "cm = confusion_matrix(targets_test, y_test_pred, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in best_estimator.classes_],\n",
    "                  columns = [i for i in best_estimator.classes_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn that helps with aesthetically pleasing plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(df_cm, annot = True)\n",
    "plt.title(\"confusion matrix for the test set\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted Label\", fontsize = 20)\n",
    "plt.ylabel(\"True Label\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(targets_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26175a51",
   "metadata": {},
   "source": [
    "So far, we have a trained random forest classifier which can classify new sequences into the top 6 most frequent classes and an unknown class if it is not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"high_level_substr\"] == 'mono/di/trisaccharide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"high_level_substr\"] == 'mono/di/trisaccharide'][\"low_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data[\"high_level_substr\"].isin([\"multiple_substrates\", 'mono/di/trisaccharide'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"sig_gene_seq\"], data[\"high_level_substr\"],\n",
    "                                                    test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function that takes in the data and number of classes\n",
    "def model_by_classes(num_classes, data, both = False, split_on_bar = False): \n",
    "    # get the frequency counts\n",
    "    all_classes = list(data.high_level_substr.value_counts().keys())\n",
    "    # remove multiple substrates\n",
    "    all_classes = [classes for classes in all_classes if classes not in [\"multiple_substrates\"]]\n",
    "    # suppose using the top 2\n",
    "    keep_these_many = num_classes\n",
    "    # top_k_classes\n",
    "    top_k = all_classes[:keep_these_many]\n",
    "    # not top two\n",
    "    not_top_k = [target for target in all_classes if target not in top_k]\n",
    "    # get the data for the top k classes\n",
    "    top_k_data = data[data.high_level_substr.isin(top_k)].reset_index(drop = True)\n",
    "    # get the data for the non top_k classes\n",
    "    not_top_k_data = data[data.high_level_substr.isin(not_top_k)].reset_index(drop = True)\n",
    "    # give the same label to all the targets of the not_top_k_data\n",
    "    not_top_k_data[\"high_level_substr\"] = \"other\"\n",
    "    # stack the top k and the not top k data together\n",
    "    all_data = pd.concat([top_k_data, not_top_k_data], ignore_index = True)\n",
    "    \n",
    "    if split_on_bar == False:\n",
    "        # instantiate the vectorizer again\n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)\n",
    "    \n",
    "    else: \n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).replace(\"|\", \",\").split(','), lowercase = False)\n",
    "    \n",
    "    # pipeline\n",
    "    clf = Pipeline([('countvectorizer',vectorizer),('rf',RandomForestClassifier(n_jobs = 6))])\n",
    "    # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "    param_grid = {\n",
    "    'countvectorizer__min_df': [1,2],\n",
    "    'rf__n_estimators': [100,200,400], \n",
    "    'rf__max_features': [\"auto\", \"log2\"]\n",
    "    }\n",
    "    # fit the search\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=7 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "    \n",
    "    # if both gene seq and category seq\n",
    "    \n",
    "    if both == True: \n",
    "        # fit the grid search\n",
    "        search.fit(all_data[\"sig_gene_seq\"] + \",\" + all_data[\"category_sequence\"], all_data[\"high_level_substr\"])\n",
    "    else: \n",
    "        search.fit(all_data[\"sig_gene_seq\"], all_data[\"high_level_substr\"])\n",
    "    # best score\n",
    "    best_score = search.best_score_\n",
    "    # std error\n",
    "    std_accuracy = search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]\n",
    "    vectorizer.fit_transform(all_data[\"sig_gene_seq\"])\n",
    "    print(len(vectorizer.vocabulary_))\n",
    "    return num_classes, best_score, std_accuracy, search.best_estimator_, top_k, not_top_k, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([pd.DataFrame(X_train.values), pd.DataFrame(y_train.values)], ignore_index = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns = [\"sig_gene_seq\", \"high_level_substr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef52027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function with 6 classes and only train data\n",
    "num_classes, best_score, std_accuracy, best_estimator_, top_k, not_top_k, vectorizer = model_by_classes(5, data_train, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57872d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score and std error\n",
    "best_score, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column change the original targets to top 6 + unknown\n",
    "targets_train = [target if target in top_k else \"other\" for target in data_train[\"high_level_substr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0377a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit this best estimator\n",
    "best_estimator.fit(data_train[[\"sig_gene_seq\"]].values, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f557aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(targets_train, best_estimator.predict(data_train[[\"sig_gene_seq\"]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac498386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions for test\n",
    "y_test_pred = best_estimator.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0620242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8919e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column change the original targets to top 6 + unknown\n",
    "targets_test = [target if target in top_k else \"other\" for target in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.concat([pd.DataFrame(X_test.values), pd.DataFrame(targets_test)], ignore_index = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c091b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns = [\"sig_gene_seq\", \"high_level_substr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73637e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column change the original targets to top 6 + unknown\n",
    "# targets_test = [target if target in top_k else \"other\" for target in data_test[\"high_level_substr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b1487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the array oaf confusion matrix\n",
    "cm = confusion_matrix(targets_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in best_estimator.classes_],\n",
    "                  columns = [i for i in best_estimator.classes_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn that helps with aesthetically pleasing plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(df_cm, annot = True)\n",
    "plt.title(\"confusion matrix for the test set\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted Label\", fontsize = 20)\n",
    "plt.ylabel(\"True Label\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a2d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(targets_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26175a51",
   "metadata": {},
   "source": [
    "So far, we have a trained random forest classifier which can classify new sequences into the top 6 most frequent classes and an unknown class if it is not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5ddc9",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d664f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca6a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic function that takes in the data and number of classes\n",
    "def model_by_classes(num_classes, data, both = True, split_on_bar = False): \n",
    "    # get the frequency counts\n",
    "    all_classes = list(data.high_level_substr.value_counts().keys())\n",
    "    # remove multiple substrates\n",
    "    all_classes = [classes for classes in all_classes if classes not in [\"multiple_substrates\"]]\n",
    "    # suppose using the top 2\n",
    "    keep_these_many = num_classes\n",
    "    # top_k_classes\n",
    "    top_k = all_classes[:keep_these_many]\n",
    "    # not top two\n",
    "    not_top_k = [target for target in all_classes if target not in top_k]\n",
    "    # get the data for the top k classes\n",
    "    top_k_data = data[data.high_level_substr.isin(top_k)].reset_index(drop = True)\n",
    "    # get the data for the non top_k classes\n",
    "    not_top_k_data = data[data.high_level_substr.isin(not_top_k)].reset_index(drop = True)\n",
    "    # give the same label to all the targets of the not_top_k_data\n",
    "    not_top_k_data[\"high_level_substr\"] = \"other\"\n",
    "    # stack the top k and the not top k data together\n",
    "    all_data = pd.concat([top_k_data, not_top_k_data], ignore_index = True)\n",
    "    \n",
    "    if split_on_bar == False:\n",
    "        # instantiate the vectorizer again\n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)\n",
    "    \n",
    "    else: \n",
    "        vectorizer = CountVectorizer(tokenizer=lambda x: str(x).replace(\"|\", \",\").split(','), lowercase = False)\n",
    "    \n",
    "    # pipeline\n",
    "    clf = Pipeline([('countvectorizer',vectorizer),('nn',KNeighborsClassifier(n_jobs = 6))])\n",
    "    # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "    param_grid = {\n",
    "    'countvectorizer__min_df': [1,2],\n",
    "    'nn__n_neighbors': [5, 10, 15], \n",
    "    'nn__weights': [\"uniform\", \"distance\"]\n",
    "    }\n",
    "    # fit the search\n",
    "    search = GridSearchCV(clf, param_grid, n_jobs=7 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "    \n",
    "    # if both gene seq and category seq\n",
    "    \n",
    "    if both == True: \n",
    "        # fit the grid search\n",
    "        search.fit(all_data[\"sig_gene_seq\"] + \",\" + all_data[\"category_sequence\"], all_data[\"high_level_substr\"])\n",
    "    else: \n",
    "        search.fit(all_data[\"sig_gene_seq\"], all_data[\"high_level_substr\"])\n",
    "    # best score\n",
    "    best_score = search.best_score_\n",
    "    # std error\n",
    "    std_accuracy = search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]\n",
    "    return num_classes, best_score, std_accuracy, search.best_estimator_, top_k, not_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([pd.DataFrame(X_train.values), pd.DataFrame(y_train.values)], ignore_index = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns = [\"sig_gene_seq\", \"high_level_substr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ed974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function with 6 classes and only train data\n",
    "num_classes, best_score, std_accuracy, best_estimator_, top_k, not_top_k = model_by_classes(6, data_train, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best score and std error\n",
    "best_score, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a80cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2750f",
   "metadata": {},
   "source": [
    "### Will SMOTE help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ee5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(data_train[\"sig_gene_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b966ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = vectorizer.transform(data_train[\"sig_gene_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_seq = vectorizer.transform(data_test[\"sig_gene_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978305a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sm.fit_resample(X_train_seq, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d612122",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bae80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = rf.predict(X_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(targets_test == y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6bf0f7",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"sig_gene_seq\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get an idea about the lengths first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(seq.split(\",\")) for seq in data_train[\"sig_gene_seq\"].values])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edec9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98911d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have an input layer\n",
    "input_layer = tf.keras.layers.Input(shape = (), dtype = tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07140a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique([gene for seq in data_train[\"sig_gene_seq\"].values for gene in seq.split(\",\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = [seq.replace(\",\", \" \") for seq in data_train[\"sig_gene_seq\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_seq = [seq.replace(\",\", \" \") for seq in data_test[\"sig_gene_seq\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass this to a vectorization layer\n",
    "# but first make a vectorization layer\n",
    "text_vec_layer = tf.keras.layers.TextVectorization(max_tokens = max_tokens, output_mode = \"int\",\n",
    "                                                  output_sequence_length=15, standardize = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec_layer.adapt(X_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the input through this text vectorization layer\n",
    "vectorized_text = text_vec_layer(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an embedding layer\n",
    "emb_layer = tf.keras.layers.Embedding(max_tokens, 32, mask_zero = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the vectorized text through the embedding layer\n",
    "emb_output = emb_layer(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a recurrent layer\n",
    "gru_layer = tf.keras.layers.GRU(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the emb output through the gru\n",
    "gru_output = gru_layer(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7067429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification layer\n",
    "classification_layer = tf.keras.layers.Dense(len(np.unique(targets_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd9a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class output\n",
    "class_output = classification_layer(gru_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76731365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the model\n",
    "model = tf.keras.models.Model(input_layer, class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a801073",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "             optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3), \n",
    "             metrics=tf.keras.metrics.SparseCategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41974bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = le.fit_transform(targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_test = le.transform(targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44578ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87a1e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(data_train[[\"sig_gene_seq\"]].values, np.array(targets_train), verbose = 1, batch_size = 8, \n",
    "         validation_data = (data_test[[\"sig_gene_seq\"]].values, np.array(targets_test)), \n",
    "         epochs = 200, callbacks = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\", \n",
    "                                                                   patience = 50, mode = \"min\",\n",
    "                                                                    restore_best_weights = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3f559",
   "metadata": {},
   "source": [
    "### Few Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82d52a",
   "metadata": {},
   "source": [
    "**High Level Goal** - We will handle the classes we lumped in the unknown class using few shot learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown classes\n",
    "not_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b00e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get those data from the train data\n",
    "not_top_k_data_train = data_train[data_train.target.isin(not_top_k)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_k_data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "not_top_k_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_k_data_train[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get those data from the test data\n",
    "not_top_k_data_test = data_test[data_test.target.isin(not_top_k)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c65ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_k_data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "not_top_k_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_learn import NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d701e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca143d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier again\n",
    "clf = Pipeline([('countvectorizer', CountVectorizer(tokenizer=lambda x: x.split(','))),\n",
    "                ('ft', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)), \n",
    "                ('nca', NCA()),\n",
    "                ('rf', RandomForestClassifier(n_jobs = 6))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96bd2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'countvectorizer__min_df': [1,2,3],\n",
    "    'rf__n_estimators': [100,200,400], \n",
    "    'rf__max_features': [\"auto\", \"log2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8397854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the search\n",
    "search = GridSearchCV(clf, param_grid, n_jobs=6 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "search.fit(not_top_k_data_train[\"sequence\"], not_top_k_data_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52216984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean average accuracy\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88738bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error\n",
    "search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best estimator\n",
    "best_estimator = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5532805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit again\n",
    "best_estimator.fit(not_top_k_data_train[\"sequence\"], not_top_k_data_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58912797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicitions on test\n",
    "y_test_pred = best_estimator.predict(not_top_k_data_test[\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8335274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the array of confusion matrix\n",
    "cm = confusion_matrix(not_top_k_data_test[\"target\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is the missing class\n",
    "missing_classes = [classes for classes in best_estimator.classes_ if classes not in np.unique(not_top_k_data_test[\"target\"])]\n",
    "\n",
    "missing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in best_estimator.classes_ if i not in missing_classes],\n",
    "                  columns = [i for i in best_estimator.classes_ if i not in missing_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b92588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(df_cm, annot = True)\n",
    "plt.title(\"confusion matrix for the test set\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted Label\", fontsize = 20)\n",
    "plt.ylabel(\"True Label\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16905cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118337cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(not_top_k_data_test[\"target\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9bec3",
   "metadata": {},
   "source": [
    "### Maybe another random forest for the unknowns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13391e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('countvectorizer',CountVectorizer(tokenizer=lambda x: x.split(','))),\n",
    "                ('rf',RandomForestClassifier(n_jobs = 6))])\n",
    "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'countvectorizer__min_df': [1,2],\n",
    "    'rf__n_estimators': [100,200,400], \n",
    "    'rf__max_features': [\"auto\", \"log2\"]\n",
    "}\n",
    "# fit the search\n",
    "search = GridSearchCV(clf, param_grid, n_jobs=7 , verbose = 3, cv = 5, scoring = \"accuracy\")\n",
    "# fir the grid search\n",
    "search.fit(not_top_k_data_train[\"sequence\"], not_top_k_data_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean average accuracy\n",
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error\n",
    "search.cv_results_['std_test_score'][np.argmax(search.cv_results_['mean_test_score'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd67aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best estimator\n",
    "best_estimator = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit again\n",
    "best_estimator.fit(not_top_k_data_train[\"sequence\"], not_top_k_data_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicitions on test\n",
    "y_test_pred = best_estimator.predict(not_top_k_data_test[\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the array of confusion matrix\n",
    "cm = confusion_matrix(not_top_k_data_test[\"target\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d90e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in train there was one more class than the test\n",
    "best_estimator.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is the missing class\n",
    "missing_classes = [classes for classes in best_estimator.classes_ if classes not in np.unique(not_top_k_data_test[\"target\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb70be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in best_estimator.classes_ if i not in missing_classes],\n",
    "                  columns = [i for i in best_estimator.classes_ if i not in missing_classes] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6dd9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.heatmap(df_cm, annot = True)\n",
    "plt.title(\"confusion matrix for the test set\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted Label\", fontsize = 20)\n",
    "plt.ylabel(\"True Label\", fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92719bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(not_top_k_data_test[\"target\"], y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8696c38e",
   "metadata": {},
   "source": [
    "### Metric Learning and MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d941e09",
   "metadata": {},
   "source": [
    "### Try some semi supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised = pd.read_csv(\"all_unsupervised_genes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e57635",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c9c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the sequences which have atleast one gene occuring in the training data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832027a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38eb24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_genes = [gene for seq in data_train[\"sig_gene_seq\"].values for gene in seq.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738a5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_seq_to_supervised = []\n",
    "for seq in tqdm(unsupervised[\"sequence\"]): \n",
    "    unsupervised_genes = seq.split(\",\")\n",
    "    if len(set(unsupervised_genes).intersection(train_genes)) > 3:\n",
    "        unsupervised_seq_to_supervised.append(seq)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unsupervised_seq_to_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_estimator.predict(unsupervised_seq_to_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcffe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = best_estimator.predict_proba(unsupervised_seq_to_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e2e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_probs = preds_proba.max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = list(zip(unsupervised_seq_to_supervised, preds, max_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d75298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all together\n",
    "unsupervised_data_with_preds = pd.DataFrame(zipped, columns = [\"sig_gene_seq\", \"high_level_substr\", \"prediction_prob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8077a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_data_with_preds_sure = unsupervised_data_with_preds[unsupervised_data_with_preds[\"prediction_prob\"] > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_data_with_preds_sure[\"high_level_substr\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_data_with_preds_sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73593caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51237d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = rus.fit_resample(np.array(unsupervised_data_with_preds_sure[\"sig_gene_seq\"]).reshape(-1,1), \n",
    "                unsupervised_data_with_preds_sure[\"high_level_substr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: str(x).split(','), lowercase = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(data_train[\"sig_gene_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d317897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unsupervised = vectorizer.transform(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42, n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_unsupervised, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_unsupervised = vectorizer.transform(data_test[\"sig_gene_seq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862cca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_from_unsupervised = clf.predict(X_test_unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b01ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_test.values == y_test_pred_from_unsupervised)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newone",
   "language": "python",
   "name": "newone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
